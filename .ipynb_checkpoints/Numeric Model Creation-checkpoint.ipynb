{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required packages first\n",
    "require(jsonlite)\n",
    "require(httr)\n",
    "require(data.table)\n",
    "\n",
    "get_token <- function(username, password, url_site){\n",
    "    \n",
    "    post_body = list(username=username,password=password)\n",
    "    post_url_string = paste0(url_site,'/token/')\n",
    "    result = POST(post_url_string, body = post_body)\n",
    "\n",
    "    # error handling (wrong credentials)\n",
    "    if(result$status_code==400){\n",
    "        print('Check your credentials')\n",
    "        return(0)\n",
    "    }\n",
    "    else if (result$status_code==201){\n",
    "        output = content(result)\n",
    "        token = output$key\n",
    "    }\n",
    "\n",
    "    return(token)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "send_submission <- function(predictions, token, url_site, submit_now=F){\n",
    "    \n",
    "    format_check=check_format(predictions)\n",
    "    if(!format_check){\n",
    "        return(FALSE)\n",
    "    }\n",
    "    \n",
    "    post_string=\"list(\"\n",
    "    for(i in 1:length(predictions)){\n",
    "        if(i<length(predictions)){\n",
    "            post_string=sprintf(\"%s%s,\",post_string,predictions[i])\n",
    "        } else {\n",
    "            post_string=sprintf(\"%s%s)\",post_string,predictions[i])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    submission = eval(parse(text=post_string))\n",
    "    json_body = jsonlite::toJSON(submission, auto_unbox = TRUE)\n",
    "    submission=list(submission=json_body)\n",
    "    print(submission)\n",
    "\n",
    "    if(!submit_now){\n",
    "        print(\"You did not submit.\")\n",
    "        return(FALSE)      \n",
    "    }\n",
    "    \n",
    "\n",
    "    header = add_headers(c(Authorization=paste('Token',token,sep=' ')))\n",
    "    post_url_string = paste0(url_site,'/submission/')\n",
    "    result = POST(post_url_string, header, body=submission)\n",
    "    \n",
    "    if (result$status_code==201){\n",
    "        print(\"Successfully submitted. Below you can see the details of your submission\")\n",
    "    } else {\n",
    "        print(\"Could not submit. Please check the error message below, contact the assistant if needed.\")\n",
    "    }\n",
    "    \n",
    "    print(content(result))\n",
    "    \n",
    "}\n",
    "\n",
    "check_format <- function(predictions){\n",
    "    \n",
    "    if(all(is.numeric(predictions)) & all(predictions<=1)){\n",
    "        print(\"Format OK\")\n",
    "        return(TRUE)\n",
    "    } else {\n",
    "        print(\"Wrong format\")\n",
    "        return(FALSE)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# this part is main code\n",
    "subm_url = 'http://46.101.121.83'\n",
    "\n",
    "u_name = \"Miners\"\n",
    "p_word = \"NsY7hhlU9zjl8DH3\"\n",
    "submit_now = TRUE\n",
    "\n",
    "username = u_name\n",
    "password = p_word\n",
    "\n",
    "token = get_token(username=u_name, password=p_word, url=subm_url)\n",
    "# this part is where you need to provide your prediction method/function or set of R codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "library(Information)\n",
    "library(FactoMineR)\n",
    "library(caTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData<-read.csv(\"IE582_Fall20_ProjectTrain.csv\")\n",
    "\n",
    "TrainData<-TrainData[,-c(50,52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData$y=as.numeric(TrainData$y)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1659 obs. of  59 variables:\n",
      " $ x1 : int  27 30 37 33 33 29 27 28 27 29 ...\n",
      " $ x2 : int  1 0 0 1 0 1 1 1 0 1 ...\n",
      " $ x3 : int  1 1 1 1 0 0 1 1 1 0 ...\n",
      " $ x4 : int  1 1 1 0 1 1 1 1 0 0 ...\n",
      " $ x5 : int  18 18 1 2 5 16 13 0 8 3 ...\n",
      " $ x6 : int  3 13 3 15 5 1 4 0 18 14 ...\n",
      " $ x7 : int  1 3 14 12 12 2 17 2 18 1 ...\n",
      " $ x8 : int  28 19 33 39 26 24 34 40 26 24 ...\n",
      " $ x9 : num  119.9 86.7 174 55 144.7 ...\n",
      " $ x10: num  154 133 128 188 151 ...\n",
      " $ x11: num  121.4 129 100.2 156.6 57.7 ...\n",
      " $ x12: int  1 0 0 1 0 0 0 0 1 0 ...\n",
      " $ x13: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x14: int  404 303 454 404 404 404 30 202 404 454 ...\n",
      " $ x15: int  1 1 1 0 1 0 1 1 1 1 ...\n",
      " $ x16: int  0 0 0 0 0 0 0 1 0 0 ...\n",
      " $ x17: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x18: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x19: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x20: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x21: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x22: int  0 1 0 0 0 0 0 0 0 0 ...\n",
      " $ x23: int  1 1 1 1 0 1 0 0 0 1 ...\n",
      " $ x24: int  0 0 0 0 0 0 1 1 0 0 ...\n",
      " $ x25: int  0 0 0 0 1 0 0 0 0 0 ...\n",
      " $ x26: int  0 0 0 1 0 0 0 0 0 0 ...\n",
      " $ x27: int  115 129 173 220 173 103 102 99 112 142 ...\n",
      " $ x28: int  0 0 0 0 0 1 0 0 0 0 ...\n",
      " $ x29: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x30: int  562 624 562 562 812 812 375 187 624 687 ...\n",
      " $ x31: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x32: int  389 266 411 289 255 466 200 910 244 611 ...\n",
      " $ x33: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x34: int  0 0 1 1 0 0 0 0 0 0 ...\n",
      " $ x35: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x36: int  0 0 0 0 512 0 0 0 0 0 ...\n",
      " $ x37: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x38: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x39: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x40: int  0 0 0 0 0 0 0 0 1 0 ...\n",
      " $ x41: int  1 1 0 1 0 1 1 1 1 1 ...\n",
      " $ x42: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x43: int  0 0 0 0 0 0 0 1 0 0 ...\n",
      " $ x44: int  1 1 1 1 1 1 0 1 1 1 ...\n",
      " $ x45: int  1 0 0 0 0 0 0 0 0 1 ...\n",
      " $ x46: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x47: int  0 0 0 0 0 1 0 0 0 0 ...\n",
      " $ x48: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x49: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x51: int  0 0 1 0 0 0 0 0 0 0 ...\n",
      " $ x53: int  0 0 1 0 1 0 0 0 0 0 ...\n",
      " $ x54: int  0 0 0 0 1 0 1 0 1 0 ...\n",
      " $ x55: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x56: int  1 1 1 1 0 1 0 0 0 1 ...\n",
      " $ x57: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x58: int  0 0 0 0 1 0 1 0 1 0 ...\n",
      " $ x59: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ x60: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ y  : num  0 0 1 0 1 1 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "spl=sample.split(TrainData$y, SplitRatio = 0.8)\n",
    "train=subset(TrainData,spl==TRUE)\n",
    "test=subset(TrainData,spl==FALSE)\n",
    "str(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_dt=function(type,actual,forecast){\n",
    "    name=type\n",
    "    n=length(actual)\n",
    "    error=actual-forecast\n",
    "    mean=mean(actual)\n",
    "    sd=sd(actual)\n",
    "    FBias=sum(error)/sum(actual)\n",
    "    MPE=sum(error/actual)/n\n",
    "    MAPE=sum(abs(error/actual))/n\n",
    "    RMSE=sqrt(sum(error^2))/n\n",
    "    MAD=sum(abs(error))/n\n",
    "    WMAPE=MAD/mean\n",
    "    l=data.frame(name,n,mean,sd,FBias,MAPE,RMSE,MAD,WMAPE)\n",
    "    return(l)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Control with Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitControl=trainControl(method = \"repeatedcv\",\n",
    "                           number = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmGrid=expand.grid(interaction.depth = c(1, 3, 5), \n",
    "                        n.trees = (1:5)*25, \n",
    "                        shrinkage = c(0.1, 0.3, 0.5),\n",
    "                        n.minobsinnode = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "\"You are trying to do regression and your outcome only has two possible values Are you trying to do classification? If so, use a 2 level factor as your outcome column.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 37: x37 has no variation.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "1659 samples\n",
       "  58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 1 times) \n",
       "Summary of sample sizes: 1493, 1493, 1493, 1493, 1493, 1493, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  RMSE       Rsquared   MAE      \n",
       "  0.1        1                   25      0.3631635  0.3348576  0.2918203\n",
       "  0.1        1                   50      0.3490925  0.3555248  0.2660736\n",
       "  0.1        1                   75      0.3462647  0.3604126  0.2631520\n",
       "  0.1        1                  100      0.3439776  0.3650268  0.2619948\n",
       "  0.1        1                  125      0.3432441  0.3669014  0.2619235\n",
       "  0.1        3                   25      0.3447244  0.3749143  0.2590548\n",
       "  0.1        3                   50      0.3393189  0.3819554  0.2456946\n",
       "  0.1        3                   75      0.3390448  0.3818354  0.2451722\n",
       "  0.1        3                  100      0.3406929  0.3761213  0.2471882\n",
       "  0.1        3                  125      0.3419759  0.3718779  0.2479881\n",
       "  0.1        5                   25      0.3416591  0.3794287  0.2505057\n",
       "  0.1        5                   50      0.3383468  0.3842879  0.2398347\n",
       "  0.1        5                   75      0.3374676  0.3883143  0.2398858\n",
       "  0.1        5                  100      0.3382146  0.3867302  0.2413554\n",
       "  0.1        5                  125      0.3399147  0.3812733  0.2434366\n",
       "  0.3        1                   25      0.3461037  0.3600849  0.2631034\n",
       "  0.3        1                   50      0.3463668  0.3552624  0.2653857\n",
       "  0.3        1                   75      0.3468682  0.3542172  0.2668017\n",
       "  0.3        1                  100      0.3471504  0.3522264  0.2681251\n",
       "  0.3        1                  125      0.3475023  0.3513175  0.2693615\n",
       "  0.3        3                   25      0.3420303  0.3703055  0.2483260\n",
       "  0.3        3                   50      0.3465748  0.3589851  0.2545235\n",
       "  0.3        3                   75      0.3518467  0.3441253  0.2589199\n",
       "  0.3        3                  100      0.3536353  0.3411404  0.2620317\n",
       "  0.3        3                  125      0.3567144  0.3342076  0.2638140\n",
       "  0.3        5                   25      0.3463358  0.3604352  0.2485847\n",
       "  0.3        5                   50      0.3534424  0.3414743  0.2554526\n",
       "  0.3        5                   75      0.3578040  0.3314733  0.2605938\n",
       "  0.3        5                  100      0.3613151  0.3262016  0.2632598\n",
       "  0.3        5                  125      0.3656297  0.3159819  0.2678087\n",
       "  0.5        1                   25      0.3484784  0.3465200  0.2677390\n",
       "  0.5        1                   50      0.3500981  0.3434759  0.2710750\n",
       "  0.5        1                   75      0.3514102  0.3394483  0.2721638\n",
       "  0.5        1                  100      0.3535143  0.3340063  0.2751330\n",
       "  0.5        1                  125      0.3538254  0.3334411  0.2757865\n",
       "  0.5        3                   25      0.3524712  0.3419767  0.2598116\n",
       "  0.5        3                   50      0.3612574  0.3259990  0.2704582\n",
       "  0.5        3                   75      0.3667053  0.3137484  0.2758297\n",
       "  0.5        3                  100      0.3753197  0.2974183  0.2843748\n",
       "  0.5        3                  125      0.3825653  0.2821478  0.2899812\n",
       "  0.5        5                   25      0.3608176  0.3277306  0.2671695\n",
       "  0.5        5                   50      0.3782630  0.2878383  0.2854115\n",
       "  0.5        5                   75      0.3897097  0.2663062  0.2943783\n",
       "  0.5        5                  100      0.3964512  0.2571456  0.2999894\n",
       "  0.5        5                  125      0.4077224  0.2398859  0.3115911\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 20\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were n.trees = 75, interaction.depth =\n",
       " 5, shrinkage = 0.1 and n.minobsinnode = 20."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAAZAAAgP9NRT5N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\nRAIQAJEABPgfcBMfXgNMcNIAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_fit=train(y ~ .-x57, data = train, \n",
    "                 method = \"gbm\", \n",
    "                 trControl = fitControl,  \n",
    "                 tuneGrid = gbmGrid,\n",
    "                 verbose=F)\n",
    "\n",
    "gbm_fit\n",
    "plot(gbm_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train=predict(gbm_fit,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "415"
      ],
      "text/latex": [
       "415"
      ],
      "text/markdown": [
       "415"
      ],
      "text/plain": [
       "[1] 415"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>name</th><th scope=col>n</th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>FBias</th><th scope=col>MAPE</th><th scope=col>RMSE</th><th scope=col>MAD</th><th scope=col>WMAPE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Performance Measure</td><td>415                </td><td>0.2474569          </td><td>0.2904989          </td><td>0.006763794        </td><td>1.215049           </td><td>0.01606674         </td><td>0.2321444          </td><td>0.9381206          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " name & n & mean & sd & FBias & MAPE & RMSE & MAD & WMAPE\\\\\n",
       "\\hline\n",
       "\t Performance Measure & 415                 & 0.2474569           & 0.2904989           & 0.006763794         & 1.215049            & 0.01606674          & 0.2321444           & 0.9381206          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| name | n | mean | sd | FBias | MAPE | RMSE | MAD | WMAPE |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Performance Measure | 415                 | 0.2474569           | 0.2904989           | 0.006763794         | 1.215049            | 0.01606674          | 0.2321444           | 0.9381206           |\n",
       "\n"
      ],
      "text/plain": [
       "  name                n   mean      sd        FBias       MAPE     RMSE      \n",
       "1 Performance Measure 415 0.2474569 0.2904989 0.006763794 1.215049 0.01606674\n",
       "  MAD       WMAPE    \n",
       "1 0.2321444 0.9381206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_dt(\"Performance Measure\", as.numeric(predictions_train), as.numeric(test$y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test=read.csv(\"IE582_Fall20_ProjectTest.csv\")\n",
    "\n",
    "final_test<-final_test[,-c(50,52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "\"You are trying to do regression and your outcome only has two possible values Are you trying to do classification? If so, use a 2 level factor as your outcome column.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "2074 samples\n",
       "  58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 1 times) \n",
       "Summary of sample sizes: 1867, 1867, 1867, 1867, 1866, 1866, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  RMSE       Rsquared   MAE      \n",
       "  0.1        1                   25      0.3611998  0.3355793  0.2893274\n",
       "  0.1        1                   50      0.3477126  0.3570390  0.2641263\n",
       "  0.1        1                   75      0.3440242  0.3636919  0.2609666\n",
       "  0.1        1                  100      0.3428839  0.3660510  0.2607485\n",
       "  0.1        1                  125      0.3419912  0.3681401  0.2604385\n",
       "  0.1        3                   25      0.3417630  0.3839875  0.2567630\n",
       "  0.1        3                   50      0.3355875  0.3928565  0.2415857\n",
       "  0.1        3                   75      0.3354655  0.3924780  0.2413285\n",
       "  0.1        3                  100      0.3359547  0.3904799  0.2423320\n",
       "  0.1        3                  125      0.3362329  0.3891073  0.2427290\n",
       "  0.1        5                   25      0.3394395  0.3856862  0.2486939\n",
       "  0.1        5                   50      0.3356289  0.3915204  0.2372208\n",
       "  0.1        5                   75      0.3351580  0.3920050  0.2363791\n",
       "  0.1        5                  100      0.3358800  0.3899632  0.2382159\n",
       "  0.1        5                  125      0.3377058  0.3839507  0.2400676\n",
       "  0.3        1                   25      0.3458234  0.3563044  0.2615419\n",
       "  0.3        1                   50      0.3442248  0.3582754  0.2623470\n",
       "  0.3        1                   75      0.3451973  0.3558059  0.2648915\n",
       "  0.3        1                  100      0.3462275  0.3529541  0.2657592\n",
       "  0.3        1                  125      0.3464691  0.3526209  0.2660333\n",
       "  0.3        3                   25      0.3399469  0.3747598  0.2447118\n",
       "  0.3        3                   50      0.3451000  0.3590177  0.2503279\n",
       "  0.3        3                   75      0.3490701  0.3470725  0.2558690\n",
       "  0.3        3                  100      0.3514990  0.3408197  0.2563268\n",
       "  0.3        3                  125      0.3534605  0.3374734  0.2584621\n",
       "  0.3        5                   25      0.3456886  0.3567319  0.2459545\n",
       "  0.3        5                   50      0.3502900  0.3455189  0.2531915\n",
       "  0.3        5                   75      0.3565113  0.3288848  0.2605499\n",
       "  0.3        5                  100      0.3572409  0.3304780  0.2618211\n",
       "  0.3        5                  125      0.3624569  0.3173086  0.2673030\n",
       "  0.5        1                   25      0.3446670  0.3572821  0.2639537\n",
       "  0.5        1                   50      0.3477724  0.3497736  0.2696108\n",
       "  0.5        1                   75      0.3480362  0.3474035  0.2683977\n",
       "  0.5        1                  100      0.3477776  0.3495839  0.2696749\n",
       "  0.5        1                  125      0.3477615  0.3488862  0.2695368\n",
       "  0.5        3                   25      0.3504340  0.3451557  0.2540226\n",
       "  0.5        3                   50      0.3633772  0.3133742  0.2634341\n",
       "  0.5        3                   75      0.3685225  0.3015815  0.2698758\n",
       "  0.5        3                  100      0.3750803  0.2952184  0.2753091\n",
       "  0.5        3                  125      0.3778752  0.2916297  0.2794301\n",
       "  0.5        5                   25      0.3533117  0.3459739  0.2550764\n",
       "  0.5        5                   50      0.3683932  0.3075971  0.2709009\n",
       "  0.5        5                   75      0.3830629  0.2777656  0.2838736\n",
       "  0.5        5                  100      0.3930753  0.2610830  0.2926190\n",
       "  0.5        5                  125      0.3991139  0.2522272  0.2993083\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 20\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were n.trees = 75, interaction.depth =\n",
       " 5, shrinkage = 0.1 and n.minobsinnode = 20."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAAZAAAgP9NRT5N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\nAEQCEOB/ScQgI6bcnpAAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_fit=train(y ~ .-x37, data = TrainData, \n",
    "                 method = \"gbm\", \n",
    "                 trControl = fitControl,  \n",
    "                 tuneGrid = gbmGrid,\n",
    "                 verbose=F)\n",
    "\n",
    "gbm_fit\n",
    "plot(gbm_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction=predict(gbm_fit,final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'randomForest' was built under R version 3.6.3\"randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in randomForest.default(m, y, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = y ~ ., data = train, ntree = 500, nodesize = 20) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 19\n",
       "\n",
       "          Mean of squared residuals: 0.1161138\n",
       "                    % Var explained: 37.28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest=randomForest(y~.,data=train,ntree=500,nodesize=20)\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictRandomForest=predict(random_forest,newdata=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>name</th><th scope=col>n</th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>FBias</th><th scope=col>MAPE</th><th scope=col>RMSE</th><th scope=col>MAD</th><th scope=col>WMAPE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Random Forest</td><td>415          </td><td>0.2457831    </td><td>0.4310702    </td><td>-0.01785097  </td><td>Inf          </td><td>0.01662572   </td><td>0.2378666    </td><td>0.9677904    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " name & n & mean & sd & FBias & MAPE & RMSE & MAD & WMAPE\\\\\n",
       "\\hline\n",
       "\t Random Forest & 415           & 0.2457831     & 0.4310702     & -0.01785097   & Inf           & 0.01662572    & 0.2378666     & 0.9677904    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| name | n | mean | sd | FBias | MAPE | RMSE | MAD | WMAPE |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Random Forest | 415           | 0.2457831     | 0.4310702     | -0.01785097   | Inf           | 0.01662572    | 0.2378666     | 0.9677904     |\n",
       "\n"
      ],
      "text/plain": [
       "  name          n   mean      sd        FBias       MAPE RMSE       MAD      \n",
       "1 Random Forest 415 0.2457831 0.4310702 -0.01785097 Inf  0.01662572 0.2378666\n",
       "  WMAPE    \n",
       "1 0.9677904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_dt(\"Random Forest\",as.numeric(test$y),as.numeric(PredictRandomForest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in randomForest.default(m, y, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = y ~ ., data = TrainData, ntree = 500,      nodesize = 20) \n",
       "               Type of random forest: regression\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 19\n",
       "\n",
       "          Mean of squared residuals: 0.1135454\n",
       "                    % Var explained: 38.69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_final=randomForest(y~.,data=TrainData,ntree=500,nodesize=20)\n",
    "random_forest_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf_final=predict(random_forest_final,final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'GGally' was built under R version 3.6.3\"Registered S3 method overwritten by 'GGally':\n",
      "  method from   \n",
      "  +.gg   ggplot2\n",
      "Warning message:\n",
      "\"package 'rattle' was built under R version 3.6.3\"Loading required package: bitops\n",
      "Rattle: A free graphical interface for data science with R.\n",
      "Version 5.4.0 Copyright (c) 2006-2020 Togaware Pty Ltd.\n",
      "Type 'rattle()' to shake, rattle, and roll your data.\n",
      "\n",
      "Attaching package: 'rattle'\n",
      "\n",
      "The following object is masked from 'package:randomForest':\n",
      "\n",
      "    importance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(rpart)\n",
    "library(GGally, quietly=TRUE)\n",
    "library(rattle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0  </td><td>1.5</td></tr>\n",
       "\t<tr><td>3  </td><td>0.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t 0   & 1.5\\\\\n",
       "\t 3   & 0.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0   | 1.5 |\n",
       "| 3   | 0.0 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 0    1.5 \n",
       "[2,] 3    0.0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PenaltyMatrix = matrix(c(0,1.5,3,0), byrow=TRUE, nrow=2)\n",
    "PenaltyMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>x23</dt>\n",
       "\t\t<dd>55.7636433503025</dd>\n",
       "\t<dt>x56</dt>\n",
       "\t\t<dd>49.3053384541902</dd>\n",
       "\t<dt>x54</dt>\n",
       "\t\t<dd>33.1248541445757</dd>\n",
       "\t<dt>x30</dt>\n",
       "\t\t<dd>25.2871779917849</dd>\n",
       "\t<dt>x17</dt>\n",
       "\t\t<dd>23.8887837017485</dd>\n",
       "\t<dt>x42</dt>\n",
       "\t\t<dd>23.2796369039288</dd>\n",
       "\t<dt>x44</dt>\n",
       "\t\t<dd>19.3749146883367</dd>\n",
       "\t<dt>x32</dt>\n",
       "\t\t<dd>18.3771626217501</dd>\n",
       "\t<dt>x48</dt>\n",
       "\t\t<dd>7.61240306327089</dd>\n",
       "\t<dt>x36</dt>\n",
       "\t\t<dd>7.30047718863267</dd>\n",
       "\t<dt>x38</dt>\n",
       "\t\t<dd>1.39998217255556</dd>\n",
       "\t<dt>x35</dt>\n",
       "\t\t<dd>1.13748551520139</dd>\n",
       "\t<dt>x19</dt>\n",
       "\t\t<dd>0.874988857847232</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[x23] 55.7636433503025\n",
       "\\item[x56] 49.3053384541902\n",
       "\\item[x54] 33.1248541445757\n",
       "\\item[x30] 25.2871779917849\n",
       "\\item[x17] 23.8887837017485\n",
       "\\item[x42] 23.2796369039288\n",
       "\\item[x44] 19.3749146883367\n",
       "\\item[x32] 18.3771626217501\n",
       "\\item[x48] 7.61240306327089\n",
       "\\item[x36] 7.30047718863267\n",
       "\\item[x38] 1.39998217255556\n",
       "\\item[x35] 1.13748551520139\n",
       "\\item[x19] 0.874988857847232\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "x23\n",
       ":   55.7636433503025x56\n",
       ":   49.3053384541902x54\n",
       ":   33.1248541445757x30\n",
       ":   25.2871779917849x17\n",
       ":   23.8887837017485x42\n",
       ":   23.2796369039288x44\n",
       ":   19.3749146883367x32\n",
       ":   18.3771626217501x48\n",
       ":   7.61240306327089x36\n",
       ":   7.30047718863267x38\n",
       ":   1.39998217255556x35\n",
       ":   1.13748551520139x19\n",
       ":   0.874988857847232\n",
       "\n"
      ],
      "text/plain": [
       "       x23        x56        x54        x30        x17        x42        x44 \n",
       "55.7636434 49.3053385 33.1248541 25.2871780 23.8887837 23.2796369 19.3749147 \n",
       "       x32        x48        x36        x38        x35        x19 \n",
       "18.3771626  7.6124031  7.3004772  1.3999822  1.1374855  0.8749889 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAWlBMVEUAAABNTU1oaGhtbW10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\nQID/B+ODIG1CPA2JAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DecTree_pen = rpart(y ~ .,\n",
    "                   data=train, parms=list(loss=PenaltyMatrix),\n",
    "                   cp=0.01)\n",
    "fancyRpartPlot(DecTree_pen)\n",
    "DecTree_pen$variable.importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalized_tree=predict(DecTree_pen,newdata=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performanca Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTree_pen = rpart(y ~ .,\n",
    "                   data=TrainData, parms=list(loss=PenaltyMatrix),\n",
    "                   cp=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalized_tree_final=predict(DecTree_pen,newdata=final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Attaching package: 'Matrix'\n",
      "\n",
      "The following objects are masked from 'package:tidyr':\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "Attaching package: 'foreach'\n",
      "\n",
      "The following objects are masked from 'package:purrr':\n",
      "\n",
      "    accumulate, when\n",
      "\n",
      "Loaded glmnet 2.0-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData=as.data.table(TrainData)\n",
    "final_test=as.data.table(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=as.data.table(train)\n",
    "test=as.data.table(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_spam=data.matrix(train[complete.cases(train),-c(\"y\"),with=F])\n",
    "\n",
    "result_vec_spam=as.vector(t(train[complete.cases(train),\"y\"]))\n",
    "\n",
    "cvfit_spam=cv.glmnet(train_mat_spam,result_vec_spam,nfolds = 10,type.measure = \"mse\")\n",
    "\n",
    "test_mat_spam=data.matrix(test[,-c(\"y\")])\n",
    "\n",
    "lasso_model <- glmnet(train_mat_spam,result_vec_spam, alpha = 1, lambda = cvfit_spam$lambda.min, standardize = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_predicts_train <- predict(lasso_model, s = cvfit_spam$lambda.min, newx = test_mat_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_spam=data.matrix(TrainData[complete.cases(TrainData),-c(\"y\"),with=F])\n",
    "\n",
    "result_vec_spam=as.vector(t(TrainData[complete.cases(TrainData),\"y\"]))\n",
    "\n",
    "cvfit_spam=cv.glmnet(train_mat_spam,result_vec_spam,nfolds = 10,type.measure = \"mse\")\n",
    "\n",
    "test_mat_spam=data.matrix(final_test[,-c(\"y\")])\n",
    "\n",
    "lasso_model <- glmnet(train_mat_spam,result_vec_spam, alpha = 1, lambda = cvfit_spam$lambda.min, standardize = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_predicts <- predict(lasso_model, s = cvfit_spam$lambda.min, newx = test_mat_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_bin=ifelse(final_prediction<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf_final_bin=ifelse(predictions_rf_final<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalized_tree_final_bin=ifelse(penalized_tree_final<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_predicts_bin=ifelse(lasso_predicts<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_num=(final_prediction+predictions_rf_final+lasso_predicts)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_num_bin=ifelse(avg_num<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_avg=(ifelse(final_prediction>0.5,(final_prediction+(final_prediction-0.5)*3),final_prediction)+\n",
    "    ifelse(predictions_rf_final>0.5,(predictions_rf_final+(predictions_rf_final-0.5)*3),predictions_rf_final)+\n",
    "    ifelse(lasso_predicts>0.5,(lasso_predicts+(lasso_predicts-0.5)*3),lasso_predicts))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_avg_bin=ifelse(cus_avg<0.485,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_avg=ifelse(final_prediction_bin==1|predictions_rf_final_bin==1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(final_prediction+predictions_rf_final)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>4:</strong> -0.00384322864428102"
      ],
      "text/latex": [
       "\\textbf{4:} -0.00384322864428102"
      ],
      "text/markdown": [
       "**4:** -0.00384322864428102"
      ],
      "text/plain": [
       "           4 \n",
       "-0.003843229 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Named num 0.0482\n",
      " - attr(*, \"names\")= chr \"1\"\n"
     ]
    }
   ],
   "source": [
    "str(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:length(a)){\n",
    "    if(a[i]<0){\n",
    "        a[i]=0\n",
    "    }\n",
    "    if(a[i]>1){\n",
    "        a[i]=1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_num=array(1:2073)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:length(final_prediction)){\n",
    "    if(two_avg[i]==1 | cus_avg_bin[i]==1 | avg_num[i]==1){\n",
    "        last_num[i]=1\n",
    "    }\n",
    "    else{\n",
    "        last_num[i]=0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(kernlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machines with Linear Kernel \n",
       "\n",
       "1659 samples\n",
       "  58 predictor\n",
       "   2 classes: '0', '1' \n",
       "\n",
       "Pre-processing: centered (58), scaled (58) \n",
       "Resampling: Cross-Validated (10 fold, repeated 1 times) \n",
       "Summary of sample sizes: 1494, 1494, 1492, 1493, 1493, 1493, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy   Kappa    \n",
       "  0.8306363  0.5047685\n",
       "\n",
       "Tuning parameter 'C' was held constant at a value of 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm1 <- train(as.factor(y) ~., data = train, method = \"svmLinear\",\n",
    "              trControl = fitControl,  preProcess = c(\"center\",\"scale\"))\n",
    "#View the model\n",
    "svm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_pred_train=predict(svm1,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 289  42\n",
       "         1  24  60\n",
       "                                          \n",
       "               Accuracy : 0.841           \n",
       "                 95% CI : (0.8022, 0.8748)\n",
       "    No Information Rate : 0.7542          \n",
       "    P-Value [Acc > NIR] : 1.167e-05       \n",
       "                                          \n",
       "                  Kappa : 0.5439          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.03639         \n",
       "                                          \n",
       "              Precision : 0.8731          \n",
       "                 Recall : 0.9233          \n",
       "                     F1 : 0.8975          \n",
       "             Prevalence : 0.7542          \n",
       "         Detection Rate : 0.6964          \n",
       "   Detection Prevalence : 0.7976          \n",
       "      Balanced Accuracy : 0.7558          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = as.factor(svm1_pred_train), reference = as.factor(test$y), mode = \"prec_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machines with Radial Basis Function Kernel \n",
       "\n",
       "1659 samples\n",
       "  58 predictor\n",
       "   2 classes: '0', '1' \n",
       "\n",
       "Pre-processing: centered (58), scaled (58) \n",
       "Resampling: Cross-Validated (10 fold, repeated 1 times) \n",
       "Summary of sample sizes: 1493, 1494, 1493, 1494, 1493, 1493, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  C       Accuracy   Kappa    \n",
       "    0.25  0.8100959  0.3656509\n",
       "    0.50  0.8178873  0.4373516\n",
       "    1.00  0.8233345  0.4656688\n",
       "    2.00  0.8185007  0.4617226\n",
       "    4.00  0.8197128  0.4728209\n",
       "    8.00  0.8004245  0.4352917\n",
       "   16.00  0.7865944  0.4031460\n",
       "   32.00  0.7811944  0.3976901\n",
       "   64.00  0.7757726  0.3887708\n",
       "  128.00  0.7757618  0.3972768\n",
       "\n",
       "Tuning parameter 'sigma' was held constant at a value of 0.01059891\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were sigma = 0.01059891 and C = 1."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm3 <- train(as.factor(y) ~., data = train, method = \"svmRadial\",\n",
    "              trControl = fitControl, preProcess = c(\"center\",\"scale\"), tuneLength = 10)\n",
    "# Print the best tuning parameter sigma and C that maximizes model accuracy\n",
    "svm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm3_pred_train=predict(svm3,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 296  46\n",
       "         1  17  56\n",
       "                                        \n",
       "               Accuracy : 0.8482        \n",
       "                 95% CI : (0.81, 0.8813)\n",
       "    No Information Rate : 0.7542        \n",
       "    P-Value [Acc > NIR] : 2.005e-06     \n",
       "                                        \n",
       "                  Kappa : 0.5471        \n",
       "                                        \n",
       " Mcnemar's Test P-Value : 0.0004192     \n",
       "                                        \n",
       "              Precision : 0.8655        \n",
       "                 Recall : 0.9457        \n",
       "                     F1 : 0.9038        \n",
       "             Prevalence : 0.7542        \n",
       "         Detection Rate : 0.7133        \n",
       "   Detection Prevalence : 0.8241        \n",
       "      Balanced Accuracy : 0.7474        \n",
       "                                        \n",
       "       'Positive' Class : 0             \n",
       "                                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = as.factor(svm3_pred_train), reference = as.factor(test$y), mode = \"prec_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: x37\"Warning message in .local(x, ...):\n",
      "\"Variable(s) `' constant. Cannot scale data.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machines with Polynomial Kernel \n",
       "\n",
       "1659 samples\n",
       "  58 predictor\n",
       "   2 classes: '0', '1' \n",
       "\n",
       "Pre-processing: centered (58), scaled (58) \n",
       "Resampling: Cross-Validated (10 fold, repeated 1 times) \n",
       "Summary of sample sizes: 1493, 1493, 1493, 1494, 1493, 1492, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  degree  scale  C     Accuracy   Kappa     \n",
       "  1       0.001  0.25  0.7546751  0.00000000\n",
       "  1       0.001  0.50  0.7588993  0.02555856\n",
       "  1       0.001  1.00  0.7582969  0.02433686\n",
       "  1       0.001  2.00  0.8004514  0.29789436\n",
       "  1       0.010  0.25  0.8076766  0.35849954\n",
       "  1       0.010  0.50  0.8299950  0.47680729\n",
       "  1       0.010  1.00  0.8293781  0.48848251\n",
       "  1       0.010  2.00  0.8305829  0.49357417\n",
       "  1       0.100  0.25  0.8281769  0.48854614\n",
       "  1       0.100  0.50  0.8263841  0.49018388\n",
       "  1       0.100  1.00  0.8269792  0.49535709\n",
       "  1       0.100  2.00  0.8318094  0.50819817\n",
       "  1       1.000  0.25  0.8312106  0.50650138\n",
       "  1       1.000  0.50  0.8300057  0.50367569\n",
       "  1       1.000  1.00  0.8282021  0.49882334\n",
       "  1       1.000  2.00  0.8300203  0.50516792\n",
       "  2       0.001  0.25  0.7582969  0.02433686\n",
       "  2       0.001  0.50  0.7582969  0.02433686\n",
       "  2       0.001  1.00  0.8034707  0.31374153\n",
       "  2       0.001  2.00  0.8299769  0.47085852\n",
       "  2       0.010  0.25  0.8269684  0.46483252\n",
       "  2       0.010  0.50  0.8239636  0.46782366\n",
       "  2       0.010  1.00  0.8215467  0.47010769\n",
       "  2       0.010  2.00  0.8227479  0.47801497\n",
       "  2       0.100  0.25  0.7859932  0.41274319\n",
       "  2       0.100  0.50  0.7721486  0.38504578\n",
       "  2       0.100  1.00  0.7631087  0.36654607\n",
       "  2       0.100  2.00  0.7498738  0.34731789\n",
       "  2       1.000  0.25  0.7335579  0.31886038\n",
       "  2       1.000  0.50  0.7335579  0.31886038\n",
       "  2       1.000  1.00  0.7335579  0.31886038\n",
       "  2       1.000  2.00  0.7335579  0.31886038\n",
       "  3       0.001  0.25  0.7582969  0.02433686\n",
       "  3       0.001  0.50  0.7805934  0.15938548\n",
       "  3       0.001  1.00  0.8191225  0.41832828\n",
       "  3       0.001  2.00  0.8311853  0.48397552\n",
       "  3       0.010  0.25  0.8227552  0.46326111\n",
       "  3       0.010  0.50  0.8179140  0.45793591\n",
       "  3       0.010  1.00  0.8173115  0.46678849\n",
       "  3       0.010  2.00  0.8149092  0.47598181\n",
       "  3       0.100  0.25  0.7775922  0.39122544\n",
       "  3       0.100  0.50  0.7745765  0.38360399\n",
       "  3       0.100  1.00  0.7745765  0.38360399\n",
       "  3       0.100  2.00  0.7745765  0.38360399\n",
       "  3       1.000  0.25  0.7854092  0.41210640\n",
       "  3       1.000  0.50  0.7854092  0.41210640\n",
       "  3       1.000  1.00  0.7854092  0.41210640\n",
       "  3       1.000  2.00  0.7854092  0.41210640\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were degree = 1, scale = 0.1 and C = 2."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm4 <- train(as.factor(y) ~., data = train, method = \"svmPoly\", \n",
    "              trControl = fitControl, preProcess = c(\"center\",\"scale\"), tuneLength = 4)\n",
    "# Print the best tuning parameter sigma and C that maximizes model accuracy\n",
    "svm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm4_pred_train=predict(svm4,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 289  45\n",
       "         1  24  57\n",
       "                                          \n",
       "               Accuracy : 0.8337          \n",
       "                 95% CI : (0.7944, 0.8683)\n",
       "    No Information Rate : 0.7542          \n",
       "    P-Value [Acc > NIR] : 5.813e-05       \n",
       "                                          \n",
       "                  Kappa : 0.5181          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.01605         \n",
       "                                          \n",
       "              Precision : 0.8653          \n",
       "                 Recall : 0.9233          \n",
       "                     F1 : 0.8934          \n",
       "             Prevalence : 0.7542          \n",
       "         Detection Rate : 0.6964          \n",
       "   Detection Prevalence : 0.8048          \n",
       "      Balanced Accuracy : 0.7411          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = as.factor(svm4_pred_train), reference = as.factor(test$y), mode = \"prec_recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Format OK\"\n",
      "$submission\n",
      "[0.0482,0.214,0.3955,0,0.6298,0.1584,0.3045,0.3882,0.0407,0.0055,0.2162,0.1585,0.0056,1,0.1376,0,0,0.0915,0.1455,0,0.0009,0.327,1,0,0.44,0.0599,0.4553,0.4898,0.3435,0.2986,0.3442,0.6634,0.0034,0.3871,0.5236,0.1608,0.736,0.9031,1,0,0.1057,0.1373,0.1096,0.6867,0.187,0.7439,0.1615,0,0.1513,0.119,0.035,0,0.167,0.3832,0.9395,0.5403,0.6464,0.5604,0.0565,0.3418,1,0,0.0201,0.1558,0.0638,0.0184,0,0.0113,0.6973,0.0683,0.69,0,0.0049,0.751,0.0075,0.1671,0.5253,0.0371,0.3303,0.0385,0.9652,0.0438,0,0.6751,0.1414,0.2047,0,0.0225,0.8999,0.2619,0.0168,0.0427,0.0867,0.7775,0.1308,0.2284,0.0389,0.0643,0.3007,0.4063,0.5801,0.0506,0.4715,0.2647,0.2868,0.42,0.0318,0.2261,0.1457,0.0277,0,0.733,0.0949,0.5972,0.2843,0.0046,0,0.3248,0.0109,0.0043,0.0278,0.0489,0.02,0.06,0.0846,0,0.0243,0.2301,0.6733,0.0588,0.4491,0.2258,0.3663,0.1489,0.3321,0.4299,0.0748,0.582,0.0442,0.549,0.2516,0.1656,0.3884,0.3711,0.2514,0.198,0.4864,0.1479,0.167,0.039,0,0.2998,0.1204,0.0328,0.0029,0.1713,0.0031,0.3952,0.1602,0.8162,0.1412,0.0612,0.046,0.0714,0.0102,0.5502,0.0443,0.5751,0,0.1097,0.5752,0.233,0.3035,0.023,0.3594,0,0.1726,0.1899,0.3687,0.9643,0.7077,0.6479,0.3824,0,0.7185,0,0,0.0566,0.1107,0.1744,0,0.4247,0.6133,0.1245,0.0007,0,0.0479,0.0152,0,0.6794,0.3774,0.1044,0.0851,0.4974,0.2317,0.4469,0,0.8869,0.0374,0.6276,0.063,0,0.0785,0.5228,0.1837,0.5589,0.084,0,0,0.0469,0.0729,0.0045,0.2045,0.5163,0.0621,0.0093,0.0849,0.814,0.2955,0,0.8479,0.0179,0.3615,0.0098,0.0042,0.0386,0.5891,0.1163,0.4481,0.5619,0.099,0.027,0.0273,0.0277,0.0173,0.014,0.6465,0.6972,0.6624,0.0135,0.0414,0.8089,0.6071,0.308,0.026,0.435,0.7266,0.1549,0.0511,0.0592,0.573,0.2295,0.0274,0.2556,0.4964,0.3253,0,0.0805,0.046,0.1222,0.2331,0.1159,0.2251,0.1803,0.0016,0.1273,0.4147,0.0297,0.2473,0.1111,0.1714,0.0323,0.1824,0.1307,0.5604,0.2893,0.062,0.3439,0.487,0.2705,0.3332,0.0366,0.3758,0.3103,0.241,0.9678,0.6605,0.0775,0.0021,0.0328,0.6776,0.0028,0.0002,0,0.0264,0,0.0577,0.1145,0.0489,0.0147,0.1444,0.3299,0.4118,0.0054,0.0001,0.6925,0.2114,0.1508,0.3966,0.5159,0.025,0.1573,0,0.1703,0.1872,0.3234,0.6262,0.4236,0.0213,0.2191,0.3744,0.1294,0.742,0.4293,0.6913,0.1307,0.3829,0.8174,0.0045,0.0692,0.0567,0.0219,0.06,0.2409,0.3127,0.0044,0.1587,0.2015,0.0371,0.0484,0.0273,0,0.082,0.8972,0.1286,0.3078,0.8127,0.0759,0.0938,0.1515,0.1294,0.0195,0.0563,0.1364,0.451,0.2291,0.6318,0,0,0.0818,0.9381,0.0522,0,0.0648,0.1185,0.772,0.0473,0.0092,0,0.1904,0.161,0.2789,0.033,0.7192,0.1112,0.0569,0.0171,0.3105,0.1237,0.3823,0,0.0464,0.6777,0.1639,0.0393,0.3046,0.0826,0,0,0,0.0504,0.9138,0.0398,0.7551,0.0561,0.3719,0.0515,0.1749,0.6113,0.0669,0.1866,0.0369,0.4315,0,0.4032,0.417,0.1475,0.9183,0.5652,0.4464,0.2556,0.5162,0.0029,0.028,0.1451,0.2494,0.0999,0.4038,0.0917,0.3608,0.5124,0.0477,0.4124,0.1891,0.6433,0.2141,0,0.1617,0.6388,0.2494,0.1438,0.1282,0.1145,0.98,0.0769,0.5725,0,0,0.6921,0.0672,0.4205,0.2055,0.0161,0.79,0.175,0,0.3986,0.32,0.8985,0.5253,0.0055,0.0603,0.1623,0.8713,0.0517,0.2927,0.1032,0.0038,0.0393,0.4811,0.2668,0.6019,0.0905,0.0482,0.4413,0,0.201,0.8654,0.3393,0,0,0.1119,0.9803,0.056,0,0.0525,0.6637,0.0346,0.3649,0.1135,0.5758,0.2821,0.6941,0.6355,0.0268,0.0065,0.8012,0,0.7074,0.0393,0.1177,0.0986,0,0,0.0703,0,0.2358,0.337,0.1177,0.0133,0.4283,0.2415,0.0334,0.0083,0,0.18,0,0.0559,0.536,0.4775,0,0.0174,0.2662,0,0.2177,0.2326,0,0.7306,0.1323,0,0.138,0,0.4228,0.6392,0.3916,0,1,0.5773,0.2685,0.1603,0.1031,0.9425,0.0104,0.1471,0.0694,0.0284,0.6362,0.6578,0.0058,0.4913,0.0135,0.0135,0.0379,0.7933,0.6364,0.3403,0.0513,0,0.0293,0.2777,0.0151,0.0414,0.0078,0.1339,0.252,0.0052,0.238,0,0.5173,0.2826,0.0078,0.193,0.2257,0.3053,0.2522,0.3816,0.4095,0.2046,0.1042,0.0436,0.005,0,0.2742,0.3515,0.1957,0.4579,0,0.1129,0.1613,0.0312,0.6835,0.2201,0,0,0,0.6871,0,0.034,0.0104,0.4346,0.0168,0.1956,0.4743,0.0008,0.1271,0.2787,1,0.1278,0.0657,0.0466,0.1787,0.3583,0.5943,0.1268,0.0121,0.6154,0,0.2717,0.1764,0.9702,0.1396,0.456,0.872,0.7065,0.2862,0.2682,0.0894,0,0.1446,0.1266,0.2086,0.0993,0.5895,0.1295,0.1967,0,0.3138,0.1236,0.0153,0.2139,0.2283,0.028,0,0.0982,0.1095,0.0011,0.1247,0.0665,0.5931,0.2206,0.0124,0.031,0.4858,0.3809,0.2544,0.1011,0.5128,0.5198,0.382,0.1517,0.5513,0,0.012,0.5459,0.1965,0.1455,0.5313,0.0704,0,0.6918,0.3869,0.092,0,0.7499,0.2983,0.4342,0,0.5921,0.3647,0.3481,0.0119,0.9301,0.089,0.14,0.1291,0.5805,0.2001,0.3117,0.0921,0.1723,0.0679,0.0786,0.3721,0.2927,0,0.4379,0.0502,0.0435,0.0284,0.1993,0.0328,0.1944,0.6534,0.1286,0.5108,0.6319,0.4508,0.0179,0.1964,0.0201,0.3668,1,0.0027,0,0.1269,0.3024,0.3103,0.7127,0.9246,0.0273,0.1502,0.2893,0.5658,0.0918,0.0007,0.0046,0.3659,0.4398,0.5446,0.01,0.2701,0.5645,0.1805,0.1332,0,0.1006,0,0.3843,0,0.0179,0,0.0755,0.4787,0.1315,0.7812,0.0623,0.5245,0.5542,0,0.0884,0.0196,0.0962,0.078,0.112,0.0114,0.6927,0.1319,0.01,0,0,0.1464,0.6152,0.0796,0.2628,0.8642,0.0754,0,0.0369,0.3996,0.3117,0,0.0183,0.5135,0.8024,0.5542,0.0414,0.938,0.2138,0.041,0.3224,0.1419,0.0016,0.319,0.0158,0,0.2834,0.4904,0.3157,0.035,0.312,0,0.1991,0.729,0,0.1527,0.0003,0.0098,0.0078,0,0.2204,0.0863,0.0083,0.1914,0.1616,0.2186,0.0028,0.444,0.0082,0.0784,0.5858,0.2375,0.0773,0,0.0295,0.3262,0.3533,0.1765,0.2656,0.4739,0.018,0.1784,0.0616,0.7858,0.4107,0.057,0.0131,0.5978,0.0147,0.1515,0.5296,0.0265,0,0.6351,0.4387,0.9796,0.3766,0.0853,0.367,0.0237,0.5512,0.168,0.887,0.012,0.5673,0.7718,0.6435,0,0.0672,0.0143,0.3906,0.0002,0.5979,0.7681,0,0.8176,0.2145,0.0299,0.0079,0,0.4967,0,0.0276,0.0084,0.2793,0.5279,0.0418,0.1707,0.3673,0.3423,0.0396,0.0556,0,0,0.2022,0.1789,0.4543,0.0681,0.3066,0.4954,0.7664,1,0.2598,0.3237,0.1612,0.0429,0.0972,0.0151,0.9915,0.22,0.523,0.5208,0.5746,0.2231,0.1738,0.2508,0.1118,0.135,0.3122,0.1026,0.1235,0.0887,0.5772,0.0026,0.39,0.5932,0.089,0.0789,0.019,0.3854,0.519,0,0.7084,0.7733,0.3999,0.03,0.0032,0.5165,0.4615,0.7992,0.0519,0.009,0.8717,0.5351,1,0.0323,0.0259,0.3414,0.1397,0.1806,0.627,1,0.0934,0.0354,0.7177,0.2195,0.0643,0.273,0.1079,0.0462,0.2156,0.3399,0.4483,0.3116,0,0.1606,0.0167,0.0079,1,0.9391,0.6811,0.1776,0.3728,0.1364,0.7638,0.1228,0.4026,0.017,0,0.7167,0.0697,0.0016,0.1062,0.0027,0,0.0303,0.3502,0.1349,0.0415,0.3207,0.6018,0.0422,0.3274,0.7961,0.3816,0.1277,0,0.9704,0.2713,0.1746,0.6605,0.8627,0.6154,0.3174,0.475,0.7282,0.2817,0.1752,0.4206,0.2837,0,0,0.0378,0.0488,0.1992,0.104,0.8713,0.2928,0.0253,0,0.667,0.0077,0.2185,0.3333,0.3169,0.2236,0.9242,0.8981,0.0067,0,0.0267,0.2356,0.1164,0.0668,0.645,0.0348,0.6929,0.2365,0.2618,0.1503,0.643,0.1667,0,0,0,0,0.1046,0.1478,0.36,0.5734,0,0.0504,0.6028,0.9704,0.2874,0.3819,0.0196,0.0879,0.5413,0.078,0.1027,0.9717,0.4519,0.6502,0.0542,0.0163,0.0951,0.1156,0.0793,0.7514,0.3324,0.4344,0.0579,0.2976,0,0.0209,0.4025,0.0089,0,0.3411,0.0198,0,0.0823,0.3171,0.1575,0.2702,0.1795,0.2553,0,0.4568,0.9414,0.2452,0.5832,0.6403,0.1315,0.0318,0.0583,0.2936,0,0.309,0.5964,0.5373,0.0446,0.0252,0.4485,0.5657,0,0.2994,0.2792,1,0.1366,0.5813,0.78,0.7903,0.056,0.1883,0.1346,0.2383,0.4321,0,0.9754,0.2536,0,0.0995,0.5312,0.1087,0.1308,0.3262,0.1274,0.0753,0.6281,0,0.1441,0.0953,0.2746,0.369,0.3699,0.7382,0.0176,0.4196,0.0386,0.2239,0.1253,0.0181,0.7386,0.4404,0.1628,0.0055,0.0464,0.0429,0.0406,1,0.2577,0.1115,0.1624,0.0034,0.1606,0.1025,0.0081,0.281,0.1609,0.4583,0,0.5432,0.0866,0.0016,0.6172,0.6366,0.1516,0.1201,0.005,0.0435,0.3752,0.0242,0.2349,0.0722,0,0.02,0.4248,0.1006,0.6038,0.7822,0.1619,0.5912,0.1879,0.4677,0.5432,0.0762,0.4001,0.2092,0.1395,0.1434,0.5904,0.3587,0.229,0.3289,0,0.224,0.4018,0.0972,0.2886,0.0195,0.3774,0.0121,0.518,0.0639,0.2422,0.0981,0.0196,0,0.0452,0.1014,0.3987,0.134,0,0,0.0313,0.3162,0.1095,0.1205,0.1448,0.346,0.1187,0.2933,0.0952,0.1195,0,0.1898,0.048,0.0646,0.0882,0.0258,0.4532,0.0847,0.0338,0.6625,0.7022,0.8215,0.1329,0.2073,0.1149,0.315,0,0,0.2855,0.0689,0,0.3942,0.4552,0.2881,0.0112,0.0356,0.6237,0.4179,0.0194,0.0802,0.1489,0.2232,0.9645,0.6229,0.264,0.1611,0.0045,0,0.6198,0.4293,0.0778,0.3939,0.0072,0.2467,0.1815,0.6861,1,0.3455,0.3329,0.1817,0.9867,0,0,0.3216,0,0.2421,0.3146,0.022,0.0239,0.3572,0.0701,0.1333,0.2967,0.0323,0.4438,0.0262,0.0374,0.4415,0.0711,0.2374,0.881,0.2258,0.3355,0.0068,0.0424,0,0.3976,0,0.0722,0.0731,0,0.3554,0.0642,0.7183,0.0814,0.1932,0.9433,0.258,0.6015,0.05,0.8513,0.8221,0.1969,0,0.1448,0.3862,0,0.1479,0.3769,0.1933,0.6239,0.0159,0,0.5878,0,0.1192,0.1067,0.1376,0.0072,0.4394,0.3831,0,0.1043,0.41,0.5898,0.6643,0.1498,0.3831,0.1824,0,0.4178,0.1883,0.0378,0.2279,0.1465,0.0349,0.3188,0.5293,0.2862,0.0881,0.8394,0.3101,0.0336,0,0.0889,0.1031,0.2168,0,0.1207,0.4013,0.1877,0,0.2652,0,0.1419,0.3238,0.0159,0,0.2332,0.0484,0.6414,0.5863,0.1909,0.1999,0.2389,0,0.508,0.387,0.2661,0.3387,0.342,0.0187,0.2715,0.1412,0.0706,0.1744,0.2033,0.4435,0.1722,0.0421,0.1085,0.1576,0,0.9393,0.216,0.3768,0.2604,0.2802,0.3821,0.1516,0.4156,0.337,0.4147,0.367,0.3245,0.1062,0.0081,0,0.0466,0.1842,0.2277,0.0875,0.3046,0.0591,0.0066,0.0025,0.1714,0.3583,0,0.4444,0.9523,0.0638,0.3579,0.1246,0.0933,0.1554,0.6471,0,0.7787,0.2196,0.0462,0.5636,0.6972,0.0031,0,0.5539,0.2369,0.6791,0.1904,0.2891,0.4365,0.4339,0.2841,0.0089,0.6173,0,0.2509,0.0432,0.7703,0.0423,0.1729,0.1722,0,0.2217,0.4601,0.12,0,0.6572,0.0899,0.1996,0.4934,0.001,0.1779,0.5226,0.0856,0,0.2499,0.3023,0.2186,0.6621,0.2306,0.1961,0,0.2406,0.3043,0,0.5362,0.2938,0.8456,0.1038,0.8375,0.0381,0.0872,0,0.9686,0.4231,0,0.0543,0,0.0863,0.1198,0.4615,0.4531,0.1111,1,0,0.1451,0.8174,0,0.1768,0.3301,0.223,0.1886,0.2511,0.4284,0.6844,0.616,0.3419,0.2203,0.1582,0.1305,0,0.007,0.0631,0.6918,0.1866,0.1657,0.0757,0.4957,0.1008,0.0657,0.8718,0.7112,0.4717,0.395,0.2875,0.0193,0.1319,0.0737,0.8926,0,0.0884,0.3059,0.3695,0,0,0.2646,0.4035,0.7287,0.3821,0.012,0.2491,0.3355,0.8159,0.0489,0.2373,0.5769,0.4988,0.1796,0.8859,0.0283,0.1194,0.8183,0.1368,0,0.3148,0.1265,0.0165,0.5323,0.1258,0.2978,0.0005,0.159,0,0.0307,0.067,0.1379,0.0437,0.0342,0.0345,0.1152,0.0014,0.0212,0.0275,0.003,0,0,0.2741,1,0.1683,0.0124,0.0236,0.4799,0.3534,0.1062,0.619,0.7254,0.0547,0.4963,0.0571,0,0.7392,0.162,0.3911,0.1868,0.3295,0.2019,0.0093,0.4086,0.0923,0.019,0.1897,0.3732,0.4236,0.1162,0.7131,0.3887,0.1466,0.0778,0.1109,0.4232,0.0174,0,0.3107,0.1971,0.1895,0.001,0.0489,0.3911,0.1556,0.7956,0.0482,0.7657,0.0622,0.9777,0,0.0027,0.1956,0.9315,0.8307,0,0.0187,0.0179,0.2051,0.4715,0,1,0.716,0.6541,0.306,0.5878,0.101,0.5564,0.3306,0.0359,0.1232,0.2771,0.4297,0.0881,0.3545,0.2696,0,0.0762,0.0004,0.4035,0.3171,0.0704,0.6093,0.0579,0.1277,0.3875,0.0411,0.235,0.0514,0,0.639,0.1613,0.0444,0.0976,0.2883,0.2915,0,0.2875,0.6354,0,0.4299,0.0118,0.034,0.1738,0.1779,0.2126,0,0.2086,0.1025,0.3378,0.1817,0.0096,0.0255,0.2212,0.4169,0.9217,0.0307,0.1393,0,0.4982,0.1168,0.2467,0.094,0.6319,0.1984,0.0176,0.0074,0.2253,0.1683,0,0.0449,0.6242,0.542,0.1231,0.0225,0,0.3804,0.1115,0.1903,0.1285,0.4599,0.0697,0.155,0.0306,0.7253,0.1006,0.0307,0.6726,0.9251,0.0461,0.3854,0.113,0,0.0145,0.1956,0.2561,0.4266,0.2429,0.4415,0.001,0.1659,0.6677,1,0.1432,0.0458,0.0156,0.391,0,0.004,0.7726,0.109,0.1516,0.3394,0.7821,0.1567,0.0109,0.2129,0.0416,0.2862,0.4812,0.757,0.173,0.2236,0,0.0734,0,0.6125,0.3377,0.022,0.2689,0.0778,0.645,0.2514,0.8484,0.0234,0.6381,0.5086,0.1547,0,0.2745,0.0505,0.1287,0.7401,0.0841,0,0.1971,0.2356,0.0855,0.0406,0.6279,0.2136,0.1349,0,0.1968,0.191,0.4427,0.24,0.0395,0.373,0.2973,0.5829,0.0101,0.0842,0.0228,0,0,0.1108,0.1439,0.7752,0.0704,0.1329,0.0053,0.9072,0.0288,0.8202,0,0.0245,0.0851,0.7471,0.5141,0.3998,1,0.0008,0.3706,0.6154,0.1174,0.0734,0.7497,0,0.0959,0.2772,0.008,0.3243,0.0463,0.3034,0.5858,0.0133,0.7146,0.0941,0.5147,0.2233,0.3456,0.6953,0,0,0,0.8099,1,0.0129,0.0061,0.0065,0.0274,0.0047,0.0815,0.0522,0.5708,0.114,0,0.7136,0.8118,0.1076,0.0714,0.6964,0.0112,0.2432,0,0.1057,0,0.2149,0.4294,0.119,0.2124,0,0.4612,0.2292,0,0.7774,0.0735,0.6311,0.6098,0.2523,0.0519,0.8866,0.0898,0.0458,0.3736,0.0064,0.2786,0.6051,0.1863,0.0221,0.3289,0,0.2054,0,0.3692,0.4332,0.439,0.0702,0,0.015,0.9722,0,0.3505,0.069,0,0.1554,0,0.2959,0.0393,0.6537,0.4246,0.555,0.0327,0,0.1899,0.008,0.4124,0.0063,0.8855,0.7462,0.9008,0.102,0.145,0.199,0.181,0.7925,0.0101,0,1,0.1186,0.684,0.5399,0,0.3679,0.0518,0.397,0.4764,0.2226,0.119,0.3613,0.3352,0.0228,0,0.5599,0.3865,0.2954,0.1531,0.1647,0.4433,0.2268,0.6706,0.183,0.1684,0.3492,0.0985,0.0209,0.7433,0,0,0.39,0.5392,0,0.0438,0.1657,0.003,1,0.0541,0.4053,0,0.1036,0.1224,0.8687,0.7707,0.5843,0,0.2929,0.0112,0.1033,0.2696,0.4529,0.8494,0.4326,0.0235,0.2001,0.1013,0.194,0,0.7184,0.8409,0.2039,0.3966,0.2567,0.0291,0.3012,0.0432,0.2282,0.2169,0.2731,0.251,0.0428,0.666,0.1801,0.0521,0.1065,0.929,0.2726,0.2246,0.1372,0.3204,0.0138,0.5542,0.9321,0.5092,0.6075,0,0.4182,0.0777,0.0315,0.6716,0.1649,0.2808,0.0037,0.0793,0.4414,0.1311,0.1327,0.2236,0.2076,0.0244,0.2928,0.2142,0.1581,0.3988,0.1984,0.3114,0.0085,0.8148,0.1737,0.3282,0.1155,0.4673,0.1686,0.4806,0.1912,0.2015,0.2177,0.5643,0.4524,0.3108,0,0.0318,0.6333,0.1056,0,0,0.1796,0.0026,0.3113,0.4165,0,0.0398,0,0.0451,0.0716,0.0391,0.15,0.1005,0.2821,0.037,0,0.3353,0.091,0.1075,0.7735,0.2979,0.8222,0.189,0,0.0592,0.2094,0.1208,0,0.2138,0.0083,0.906,0,0.1292,0.187,0.0123,0.1642,0.0363,0.1322] \n",
      "\n",
      "[1] \"Successfully submitted. Below you can see the details of your submission\"\n",
      "$url\n",
      "[1] \"http://46.101.121.83/submission/363/\"\n",
      "\n",
      "$submission\n",
      "[1] \"[0.0482, 0.214, 0.3955, 0, 0.6298, 0.1584, 0.3045, 0.3882, 0.0407, 0.0055, 0.2162, 0.1585, 0.0056, 1, 0.1376, 0, 0, 0.0915, 0.1455, 0, 0.0009, 0.327, 1, 0, 0.44, 0.0599, 0.4553, 0.4898, 0.3435, 0.2986, 0.3442, 0.6634, 0.0034, 0.3871, 0.5236, 0.1608, 0.736, 0.9031, 1, 0, 0.1057, 0.1373, 0.1096, 0.6867, 0.187, 0.7439, 0.1615, 0, 0.1513, 0.119, 0.035, 0, 0.167, 0.3832, 0.9395, 0.5403, 0.6464, 0.5604, 0.0565, 0.3418, 1, 0, 0.0201, 0.1558, 0.0638, 0.0184, 0, 0.0113, 0.6973, 0.0683, 0.69, 0, 0.0049, 0.751, 0.0075, 0.1671, 0.5253, 0.0371, 0.3303, 0.0385, 0.9652, 0.0438, 0, 0.6751, 0.1414, 0.2047, 0, 0.0225, 0.8999, 0.2619, 0.0168, 0.0427, 0.0867, 0.7775, 0.1308, 0.2284, 0.0389, 0.0643, 0.3007, 0.4063, 0.5801, 0.0506, 0.4715, 0.2647, 0.2868, 0.42, 0.0318, 0.2261, 0.1457, 0.0277, 0, 0.733, 0.0949, 0.5972, 0.2843, 0.0046, 0, 0.3248, 0.0109, 0.0043, 0.0278, 0.0489, 0.02, 0.06, 0.0846, 0, 0.0243, 0.2301, 0.6733, 0.0588, 0.4491, 0.2258, 0.3663, 0.1489, 0.3321, 0.4299, 0.0748, 0.582, 0.0442, 0.549, 0.2516, 0.1656, 0.3884, 0.3711, 0.2514, 0.198, 0.4864, 0.1479, 0.167, 0.039, 0, 0.2998, 0.1204, 0.0328, 0.0029, 0.1713, 0.0031, 0.3952, 0.1602, 0.8162, 0.1412, 0.0612, 0.046, 0.0714, 0.0102, 0.5502, 0.0443, 0.5751, 0, 0.1097, 0.5752, 0.233, 0.3035, 0.023, 0.3594, 0, 0.1726, 0.1899, 0.3687, 0.9643, 0.7077, 0.6479, 0.3824, 0, 0.7185, 0, 0, 0.0566, 0.1107, 0.1744, 0, 0.4247, 0.6133, 0.1245, 0.0007, 0, 0.0479, 0.0152, 0, 0.6794, 0.3774, 0.1044, 0.0851, 0.4974, 0.2317, 0.4469, 0, 0.8869, 0.0374, 0.6276, 0.063, 0, 0.0785, 0.5228, 0.1837, 0.5589, 0.084, 0, 0, 0.0469, 0.0729, 0.0045, 0.2045, 0.5163, 0.0621, 0.0093, 0.0849, 0.814, 0.2955, 0, 0.8479, 0.0179, 0.3615, 0.0098, 0.0042, 0.0386, 0.5891, 0.1163, 0.4481, 0.5619, 0.099, 0.027, 0.0273, 0.0277, 0.0173, 0.014, 0.6465, 0.6972, 0.6624, 0.0135, 0.0414, 0.8089, 0.6071, 0.308, 0.026, 0.435, 0.7266, 0.1549, 0.0511, 0.0592, 0.573, 0.2295, 0.0274, 0.2556, 0.4964, 0.3253, 0, 0.0805, 0.046, 0.1222, 0.2331, 0.1159, 0.2251, 0.1803, 0.0016, 0.1273, 0.4147, 0.0297, 0.2473, 0.1111, 0.1714, 0.0323, 0.1824, 0.1307, 0.5604, 0.2893, 0.062, 0.3439, 0.487, 0.2705, 0.3332, 0.0366, 0.3758, 0.3103, 0.241, 0.9678, 0.6605, 0.0775, 0.0021, 0.0328, 0.6776, 0.0028, 0.0002, 0, 0.0264, 0, 0.0577, 0.1145, 0.0489, 0.0147, 0.1444, 0.3299, 0.4118, 0.0054, 0.0001, 0.6925, 0.2114, 0.1508, 0.3966, 0.5159, 0.025, 0.1573, 0, 0.1703, 0.1872, 0.3234, 0.6262, 0.4236, 0.0213, 0.2191, 0.3744, 0.1294, 0.742, 0.4293, 0.6913, 0.1307, 0.3829, 0.8174, 0.0045, 0.0692, 0.0567, 0.0219, 0.06, 0.2409, 0.3127, 0.0044, 0.1587, 0.2015, 0.0371, 0.0484, 0.0273, 0, 0.082, 0.8972, 0.1286, 0.3078, 0.8127, 0.0759, 0.0938, 0.1515, 0.1294, 0.0195, 0.0563, 0.1364, 0.451, 0.2291, 0.6318, 0, 0, 0.0818, 0.9381, 0.0522, 0, 0.0648, 0.1185, 0.772, 0.0473, 0.0092, 0, 0.1904, 0.161, 0.2789, 0.033, 0.7192, 0.1112, 0.0569, 0.0171, 0.3105, 0.1237, 0.3823, 0, 0.0464, 0.6777, 0.1639, 0.0393, 0.3046, 0.0826, 0, 0, 0, 0.0504, 0.9138, 0.0398, 0.7551, 0.0561, 0.3719, 0.0515, 0.1749, 0.6113, 0.0669, 0.1866, 0.0369, 0.4315, 0, 0.4032, 0.417, 0.1475, 0.9183, 0.5652, 0.4464, 0.2556, 0.5162, 0.0029, 0.028, 0.1451, 0.2494, 0.0999, 0.4038, 0.0917, 0.3608, 0.5124, 0.0477, 0.4124, 0.1891, 0.6433, 0.2141, 0, 0.1617, 0.6388, 0.2494, 0.1438, 0.1282, 0.1145, 0.98, 0.0769, 0.5725, 0, 0, 0.6921, 0.0672, 0.4205, 0.2055, 0.0161, 0.79, 0.175, 0, 0.3986, 0.32, 0.8985, 0.5253, 0.0055, 0.0603, 0.1623, 0.8713, 0.0517, 0.2927, 0.1032, 0.0038, 0.0393, 0.4811, 0.2668, 0.6019, 0.0905, 0.0482, 0.4413, 0, 0.201, 0.8654, 0.3393, 0, 0, 0.1119, 0.9803, 0.056, 0, 0.0525, 0.6637, 0.0346, 0.3649, 0.1135, 0.5758, 0.2821, 0.6941, 0.6355, 0.0268, 0.0065, 0.8012, 0, 0.7074, 0.0393, 0.1177, 0.0986, 0, 0, 0.0703, 0, 0.2358, 0.337, 0.1177, 0.0133, 0.4283, 0.2415, 0.0334, 0.0083, 0, 0.18, 0, 0.0559, 0.536, 0.4775, 0, 0.0174, 0.2662, 0, 0.2177, 0.2326, 0, 0.7306, 0.1323, 0, 0.138, 0, 0.4228, 0.6392, 0.3916, 0, 1, 0.5773, 0.2685, 0.1603, 0.1031, 0.9425, 0.0104, 0.1471, 0.0694, 0.0284, 0.6362, 0.6578, 0.0058, 0.4913, 0.0135, 0.0135, 0.0379, 0.7933, 0.6364, 0.3403, 0.0513, 0, 0.0293, 0.2777, 0.0151, 0.0414, 0.0078, 0.1339, 0.252, 0.0052, 0.238, 0, 0.5173, 0.2826, 0.0078, 0.193, 0.2257, 0.3053, 0.2522, 0.3816, 0.4095, 0.2046, 0.1042, 0.0436, 0.005, 0, 0.2742, 0.3515, 0.1957, 0.4579, 0, 0.1129, 0.1613, 0.0312, 0.6835, 0.2201, 0, 0, 0, 0.6871, 0, 0.034, 0.0104, 0.4346, 0.0168, 0.1956, 0.4743, 0.0008, 0.1271, 0.2787, 1, 0.1278, 0.0657, 0.0466, 0.1787, 0.3583, 0.5943, 0.1268, 0.0121, 0.6154, 0, 0.2717, 0.1764, 0.9702, 0.1396, 0.456, 0.872, 0.7065, 0.2862, 0.2682, 0.0894, 0, 0.1446, 0.1266, 0.2086, 0.0993, 0.5895, 0.1295, 0.1967, 0, 0.3138, 0.1236, 0.0153, 0.2139, 0.2283, 0.028, 0, 0.0982, 0.1095, 0.0011, 0.1247, 0.0665, 0.5931, 0.2206, 0.0124, 0.031, 0.4858, 0.3809, 0.2544, 0.1011, 0.5128, 0.5198, 0.382, 0.1517, 0.5513, 0, 0.012, 0.5459, 0.1965, 0.1455, 0.5313, 0.0704, 0, 0.6918, 0.3869, 0.092, 0, 0.7499, 0.2983, 0.4342, 0, 0.5921, 0.3647, 0.3481, 0.0119, 0.9301, 0.089, 0.14, 0.1291, 0.5805, 0.2001, 0.3117, 0.0921, 0.1723, 0.0679, 0.0786, 0.3721, 0.2927, 0, 0.4379, 0.0502, 0.0435, 0.0284, 0.1993, 0.0328, 0.1944, 0.6534, 0.1286, 0.5108, 0.6319, 0.4508, 0.0179, 0.1964, 0.0201, 0.3668, 1, 0.0027, 0, 0.1269, 0.3024, 0.3103, 0.7127, 0.9246, 0.0273, 0.1502, 0.2893, 0.5658, 0.0918, 0.0007, 0.0046, 0.3659, 0.4398, 0.5446, 0.01, 0.2701, 0.5645, 0.1805, 0.1332, 0, 0.1006, 0, 0.3843, 0, 0.0179, 0, 0.0755, 0.4787, 0.1315, 0.7812, 0.0623, 0.5245, 0.5542, 0, 0.0884, 0.0196, 0.0962, 0.078, 0.112, 0.0114, 0.6927, 0.1319, 0.01, 0, 0, 0.1464, 0.6152, 0.0796, 0.2628, 0.8642, 0.0754, 0, 0.0369, 0.3996, 0.3117, 0, 0.0183, 0.5135, 0.8024, 0.5542, 0.0414, 0.938, 0.2138, 0.041, 0.3224, 0.1419, 0.0016, 0.319, 0.0158, 0, 0.2834, 0.4904, 0.3157, 0.035, 0.312, 0, 0.1991, 0.729, 0, 0.1527, 0.0003, 0.0098, 0.0078, 0, 0.2204, 0.0863, 0.0083, 0.1914, 0.1616, 0.2186, 0.0028, 0.444, 0.0082, 0.0784, 0.5858, 0.2375, 0.0773, 0, 0.0295, 0.3262, 0.3533, 0.1765, 0.2656, 0.4739, 0.018, 0.1784, 0.0616, 0.7858, 0.4107, 0.057, 0.0131, 0.5978, 0.0147, 0.1515, 0.5296, 0.0265, 0, 0.6351, 0.4387, 0.9796, 0.3766, 0.0853, 0.367, 0.0237, 0.5512, 0.168, 0.887, 0.012, 0.5673, 0.7718, 0.6435, 0, 0.0672, 0.0143, 0.3906, 0.0002, 0.5979, 0.7681, 0, 0.8176, 0.2145, 0.0299, 0.0079, 0, 0.4967, 0, 0.0276, 0.0084, 0.2793, 0.5279, 0.0418, 0.1707, 0.3673, 0.3423, 0.0396, 0.0556, 0, 0, 0.2022, 0.1789, 0.4543, 0.0681, 0.3066, 0.4954, 0.7664, 1, 0.2598, 0.3237, 0.1612, 0.0429, 0.0972, 0.0151, 0.9915, 0.22, 0.523, 0.5208, 0.5746, 0.2231, 0.1738, 0.2508, 0.1118, 0.135, 0.3122, 0.1026, 0.1235, 0.0887, 0.5772, 0.0026, 0.39, 0.5932, 0.089, 0.0789, 0.019, 0.3854, 0.519, 0, 0.7084, 0.7733, 0.3999, 0.03, 0.0032, 0.5165, 0.4615, 0.7992, 0.0519, 0.009, 0.8717, 0.5351, 1, 0.0323, 0.0259, 0.3414, 0.1397, 0.1806, 0.627, 1, 0.0934, 0.0354, 0.7177, 0.2195, 0.0643, 0.273, 0.1079, 0.0462, 0.2156, 0.3399, 0.4483, 0.3116, 0, 0.1606, 0.0167, 0.0079, 1, 0.9391, 0.6811, 0.1776, 0.3728, 0.1364, 0.7638, 0.1228, 0.4026, 0.017, 0, 0.7167, 0.0697, 0.0016, 0.1062, 0.0027, 0, 0.0303, 0.3502, 0.1349, 0.0415, 0.3207, 0.6018, 0.0422, 0.3274, 0.7961, 0.3816, 0.1277, 0, 0.9704, 0.2713, 0.1746, 0.6605, 0.8627, 0.6154, 0.3174, 0.475, 0.7282, 0.2817, 0.1752, 0.4206, 0.2837, 0, 0, 0.0378, 0.0488, 0.1992, 0.104, 0.8713, 0.2928, 0.0253, 0, 0.667, 0.0077, 0.2185, 0.3333, 0.3169, 0.2236, 0.9242, 0.8981, 0.0067, 0, 0.0267, 0.2356, 0.1164, 0.0668, 0.645, 0.0348, 0.6929, 0.2365, 0.2618, 0.1503, 0.643, 0.1667, 0, 0, 0, 0, 0.1046, 0.1478, 0.36, 0.5734, 0, 0.0504, 0.6028, 0.9704, 0.2874, 0.3819, 0.0196, 0.0879, 0.5413, 0.078, 0.1027, 0.9717, 0.4519, 0.6502, 0.0542, 0.0163, 0.0951, 0.1156, 0.0793, 0.7514, 0.3324, 0.4344, 0.0579, 0.2976, 0, 0.0209, 0.4025, 0.0089, 0, 0.3411, 0.0198, 0, 0.0823, 0.3171, 0.1575, 0.2702, 0.1795, 0.2553, 0, 0.4568, 0.9414, 0.2452, 0.5832, 0.6403, 0.1315, 0.0318, 0.0583, 0.2936, 0, 0.309, 0.5964, 0.5373, 0.0446, 0.0252, 0.4485, 0.5657, 0, 0.2994, 0.2792, 1, 0.1366, 0.5813, 0.78, 0.7903, 0.056, 0.1883, 0.1346, 0.2383, 0.4321, 0, 0.9754, 0.2536, 0, 0.0995, 0.5312, 0.1087, 0.1308, 0.3262, 0.1274, 0.0753, 0.6281, 0, 0.1441, 0.0953, 0.2746, 0.369, 0.3699, 0.7382, 0.0176, 0.4196, 0.0386, 0.2239, 0.1253, 0.0181, 0.7386, 0.4404, 0.1628, 0.0055, 0.0464, 0.0429, 0.0406, 1, 0.2577, 0.1115, 0.1624, 0.0034, 0.1606, 0.1025, 0.0081, 0.281, 0.1609, 0.4583, 0, 0.5432, 0.0866, 0.0016, 0.6172, 0.6366, 0.1516, 0.1201, 0.005, 0.0435, 0.3752, 0.0242, 0.2349, 0.0722, 0, 0.02, 0.4248, 0.1006, 0.6038, 0.7822, 0.1619, 0.5912, 0.1879, 0.4677, 0.5432, 0.0762, 0.4001, 0.2092, 0.1395, 0.1434, 0.5904, 0.3587, 0.229, 0.3289, 0, 0.224, 0.4018, 0.0972, 0.2886, 0.0195, 0.3774, 0.0121, 0.518, 0.0639, 0.2422, 0.0981, 0.0196, 0, 0.0452, 0.1014, 0.3987, 0.134, 0, 0, 0.0313, 0.3162, 0.1095, 0.1205, 0.1448, 0.346, 0.1187, 0.2933, 0.0952, 0.1195, 0, 0.1898, 0.048, 0.0646, 0.0882, 0.0258, 0.4532, 0.0847, 0.0338, 0.6625, 0.7022, 0.8215, 0.1329, 0.2073, 0.1149, 0.315, 0, 0, 0.2855, 0.0689, 0, 0.3942, 0.4552, 0.2881, 0.0112, 0.0356, 0.6237, 0.4179, 0.0194, 0.0802, 0.1489, 0.2232, 0.9645, 0.6229, 0.264, 0.1611, 0.0045, 0, 0.6198, 0.4293, 0.0778, 0.3939, 0.0072, 0.2467, 0.1815, 0.6861, 1, 0.3455, 0.3329, 0.1817, 0.9867, 0, 0, 0.3216, 0, 0.2421, 0.3146, 0.022, 0.0239, 0.3572, 0.0701, 0.1333, 0.2967, 0.0323, 0.4438, 0.0262, 0.0374, 0.4415, 0.0711, 0.2374, 0.881, 0.2258, 0.3355, 0.0068, 0.0424, 0, 0.3976, 0, 0.0722, 0.0731, 0, 0.3554, 0.0642, 0.7183, 0.0814, 0.1932, 0.9433, 0.258, 0.6015, 0.05, 0.8513, 0.8221, 0.1969, 0, 0.1448, 0.3862, 0, 0.1479, 0.3769, 0.1933, 0.6239, 0.0159, 0, 0.5878, 0, 0.1192, 0.1067, 0.1376, 0.0072, 0.4394, 0.3831, 0, 0.1043, 0.41, 0.5898, 0.6643, 0.1498, 0.3831, 0.1824, 0, 0.4178, 0.1883, 0.0378, 0.2279, 0.1465, 0.0349, 0.3188, 0.5293, 0.2862, 0.0881, 0.8394, 0.3101, 0.0336, 0, 0.0889, 0.1031, 0.2168, 0, 0.1207, 0.4013, 0.1877, 0, 0.2652, 0, 0.1419, 0.3238, 0.0159, 0, 0.2332, 0.0484, 0.6414, 0.5863, 0.1909, 0.1999, 0.2389, 0, 0.508, 0.387, 0.2661, 0.3387, 0.342, 0.0187, 0.2715, 0.1412, 0.0706, 0.1744, 0.2033, 0.4435, 0.1722, 0.0421, 0.1085, 0.1576, 0, 0.9393, 0.216, 0.3768, 0.2604, 0.2802, 0.3821, 0.1516, 0.4156, 0.337, 0.4147, 0.367, 0.3245, 0.1062, 0.0081, 0, 0.0466, 0.1842, 0.2277, 0.0875, 0.3046, 0.0591, 0.0066, 0.0025, 0.1714, 0.3583, 0, 0.4444, 0.9523, 0.0638, 0.3579, 0.1246, 0.0933, 0.1554, 0.6471, 0, 0.7787, 0.2196, 0.0462, 0.5636, 0.6972, 0.0031, 0, 0.5539, 0.2369, 0.6791, 0.1904, 0.2891, 0.4365, 0.4339, 0.2841, 0.0089, 0.6173, 0, 0.2509, 0.0432, 0.7703, 0.0423, 0.1729, 0.1722, 0, 0.2217, 0.4601, 0.12, 0, 0.6572, 0.0899, 0.1996, 0.4934, 0.001, 0.1779, 0.5226, 0.0856, 0, 0.2499, 0.3023, 0.2186, 0.6621, 0.2306, 0.1961, 0, 0.2406, 0.3043, 0, 0.5362, 0.2938, 0.8456, 0.1038, 0.8375, 0.0381, 0.0872, 0, 0.9686, 0.4231, 0, 0.0543, 0, 0.0863, 0.1198, 0.4615, 0.4531, 0.1111, 1, 0, 0.1451, 0.8174, 0, 0.1768, 0.3301, 0.223, 0.1886, 0.2511, 0.4284, 0.6844, 0.616, 0.3419, 0.2203, 0.1582, 0.1305, 0, 0.007, 0.0631, 0.6918, 0.1866, 0.1657, 0.0757, 0.4957, 0.1008, 0.0657, 0.8718, 0.7112, 0.4717, 0.395, 0.2875, 0.0193, 0.1319, 0.0737, 0.8926, 0, 0.0884, 0.3059, 0.3695, 0, 0, 0.2646, 0.4035, 0.7287, 0.3821, 0.012, 0.2491, 0.3355, 0.8159, 0.0489, 0.2373, 0.5769, 0.4988, 0.1796, 0.8859, 0.0283, 0.1194, 0.8183, 0.1368, 0, 0.3148, 0.1265, 0.0165, 0.5323, 0.1258, 0.2978, 0.0005, 0.159, 0, 0.0307, 0.067, 0.1379, 0.0437, 0.0342, 0.0345, 0.1152, 0.0014, 0.0212, 0.0275, 0.003, 0, 0, 0.2741, 1, 0.1683, 0.0124, 0.0236, 0.4799, 0.3534, 0.1062, 0.619, 0.7254, 0.0547, 0.4963, 0.0571, 0, 0.7392, 0.162, 0.3911, 0.1868, 0.3295, 0.2019, 0.0093, 0.4086, 0.0923, 0.019, 0.1897, 0.3732, 0.4236, 0.1162, 0.7131, 0.3887, 0.1466, 0.0778, 0.1109, 0.4232, 0.0174, 0, 0.3107, 0.1971, 0.1895, 0.001, 0.0489, 0.3911, 0.1556, 0.7956, 0.0482, 0.7657, 0.0622, 0.9777, 0, 0.0027, 0.1956, 0.9315, 0.8307, 0, 0.0187, 0.0179, 0.2051, 0.4715, 0, 1, 0.716, 0.6541, 0.306, 0.5878, 0.101, 0.5564, 0.3306, 0.0359, 0.1232, 0.2771, 0.4297, 0.0881, 0.3545, 0.2696, 0, 0.0762, 0.0004, 0.4035, 0.3171, 0.0704, 0.6093, 0.0579, 0.1277, 0.3875, 0.0411, 0.235, 0.0514, 0, 0.639, 0.1613, 0.0444, 0.0976, 0.2883, 0.2915, 0, 0.2875, 0.6354, 0, 0.4299, 0.0118, 0.034, 0.1738, 0.1779, 0.2126, 0, 0.2086, 0.1025, 0.3378, 0.1817, 0.0096, 0.0255, 0.2212, 0.4169, 0.9217, 0.0307, 0.1393, 0, 0.4982, 0.1168, 0.2467, 0.094, 0.6319, 0.1984, 0.0176, 0.0074, 0.2253, 0.1683, 0, 0.0449, 0.6242, 0.542, 0.1231, 0.0225, 0, 0.3804, 0.1115, 0.1903, 0.1285, 0.4599, 0.0697, 0.155, 0.0306, 0.7253, 0.1006, 0.0307, 0.6726, 0.9251, 0.0461, 0.3854, 0.113, 0, 0.0145, 0.1956, 0.2561, 0.4266, 0.2429, 0.4415, 0.001, 0.1659, 0.6677, 1, 0.1432, 0.0458, 0.0156, 0.391, 0, 0.004, 0.7726, 0.109, 0.1516, 0.3394, 0.7821, 0.1567, 0.0109, 0.2129, 0.0416, 0.2862, 0.4812, 0.757, 0.173, 0.2236, 0, 0.0734, 0, 0.6125, 0.3377, 0.022, 0.2689, 0.0778, 0.645, 0.2514, 0.8484, 0.0234, 0.6381, 0.5086, 0.1547, 0, 0.2745, 0.0505, 0.1287, 0.7401, 0.0841, 0, 0.1971, 0.2356, 0.0855, 0.0406, 0.6279, 0.2136, 0.1349, 0, 0.1968, 0.191, 0.4427, 0.24, 0.0395, 0.373, 0.2973, 0.5829, 0.0101, 0.0842, 0.0228, 0, 0, 0.1108, 0.1439, 0.7752, 0.0704, 0.1329, 0.0053, 0.9072, 0.0288, 0.8202, 0, 0.0245, 0.0851, 0.7471, 0.5141, 0.3998, 1, 0.0008, 0.3706, 0.6154, 0.1174, 0.0734, 0.7497, 0, 0.0959, 0.2772, 0.008, 0.3243, 0.0463, 0.3034, 0.5858, 0.0133, 0.7146, 0.0941, 0.5147, 0.2233, 0.3456, 0.6953, 0, 0, 0, 0.8099, 1, 0.0129, 0.0061, 0.0065, 0.0274, 0.0047, 0.0815, 0.0522, 0.5708, 0.114, 0, 0.7136, 0.8118, 0.1076, 0.0714, 0.6964, 0.0112, 0.2432, 0, 0.1057, 0, 0.2149, 0.4294, 0.119, 0.2124, 0, 0.4612, 0.2292, 0, 0.7774, 0.0735, 0.6311, 0.6098, 0.2523, 0.0519, 0.8866, 0.0898, 0.0458, 0.3736, 0.0064, 0.2786, 0.6051, 0.1863, 0.0221, 0.3289, 0, 0.2054, 0, 0.3692, 0.4332, 0.439, 0.0702, 0, 0.015, 0.9722, 0, 0.3505, 0.069, 0, 0.1554, 0, 0.2959, 0.0393, 0.6537, 0.4246, 0.555, 0.0327, 0, 0.1899, 0.008, 0.4124, 0.0063, 0.8855, 0.7462, 0.9008, 0.102, 0.145, 0.199, 0.181, 0.7925, 0.0101, 0, 1, 0.1186, 0.684, 0.5399, 0, 0.3679, 0.0518, 0.397, 0.4764, 0.2226, 0.119, 0.3613, 0.3352, 0.0228, 0, 0.5599, 0.3865, 0.2954, 0.1531, 0.1647, 0.4433, 0.2268, 0.6706, 0.183, 0.1684, 0.3492, 0.0985, 0.0209, 0.7433, 0, 0, 0.39, 0.5392, 0, 0.0438, 0.1657, 0.003, 1, 0.0541, 0.4053, 0, 0.1036, 0.1224, 0.8687, 0.7707, 0.5843, 0, 0.2929, 0.0112, 0.1033, 0.2696, 0.4529, 0.8494, 0.4326, 0.0235, 0.2001, 0.1013, 0.194, 0, 0.7184, 0.8409, 0.2039, 0.3966, 0.2567, 0.0291, 0.3012, 0.0432, 0.2282, 0.2169, 0.2731, 0.251, 0.0428, 0.666, 0.1801, 0.0521, 0.1065, 0.929, 0.2726, 0.2246, 0.1372, 0.3204, 0.0138, 0.5542, 0.9321, 0.5092, 0.6075, 0, 0.4182, 0.0777, 0.0315, 0.6716, 0.1649, 0.2808, 0.0037, 0.0793, 0.4414, 0.1311, 0.1327, 0.2236, 0.2076, 0.0244, 0.2928, 0.2142, 0.1581, 0.3988, 0.1984, 0.3114, 0.0085, 0.8148, 0.1737, 0.3282, 0.1155, 0.4673, 0.1686, 0.4806, 0.1912, 0.2015, 0.2177, 0.5643, 0.4524, 0.3108, 0, 0.0318, 0.6333, 0.1056, 0, 0, 0.1796, 0.0026, 0.3113, 0.4165, 0, 0.0398, 0, 0.0451, 0.0716, 0.0391, 0.15, 0.1005, 0.2821, 0.037, 0, 0.3353, 0.091, 0.1075, 0.7735, 0.2979, 0.8222, 0.189, 0, 0.0592, 0.2094, 0.1208, 0, 0.2138, 0.0083, 0.906, 0, 0.1292, 0.187, 0.0123, 0.1642, 0.0363, 0.1322]\"\n",
      "\n",
      "$user\n",
      "$user$url\n",
      "[1] \"http://46.101.121.83/group/12/\"\n",
      "\n",
      "$user$username\n",
      "[1] \"Miners\"\n",
      "\n",
      "$user$best_score\n",
      "[1] 0.8621\n",
      "\n",
      "$user$students\n",
      "[1] \"2016402000;2016402150;2017402060\"\n",
      "\n",
      "\n",
      "$competition\n",
      "[1] \"IE582-Test Data\"\n",
      "\n",
      "$auc\n",
      "[1] 0.9265549\n",
      "\n",
      "$ber\n",
      "[1] 0.7975984\n",
      "\n",
      "$score\n",
      "[1] 0.8620767\n",
      "\n",
      "$date\n",
      "[1] \"2021-02-09T12:47:03.000148+03:00\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "send_submission(a, token, url=subm_url, submit_now= submit_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
